{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b72d6a0",
   "metadata": {},
   "source": [
    "# Food Files\n",
    "\n",
    "## Introduction\n",
    "In this exercise, you will combine skills including File I/O, Lists, and Dictionary lessons in a practical example. Several of the files contain nutritional data created from a column-orientated database.\n",
    "\n",
    "Each entry links by position in the file to the foods column. The foods column was the key, but something happened to cause issues in the data transfer. Before coding each part, be sure to pseudocode or create a flowchart for the needed steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee6ec49",
   "metadata": {},
   "source": [
    "## Part 1: Read in the Data\n",
    "Read in the provided data from multiple files using one of the tools explained in the File I/O lesson and place these into Lists. Look at the files before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c415f36",
   "metadata": {},
   "source": [
    "To facilitate reading in multiple data files, we will created a function `DataReadIn()` to read in specific files.\n",
    "\n",
    "**In function**\n",
    "* Open the file in read mode\n",
    "* load the data to local variable\n",
    "* close the file\n",
    "* return the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb07399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data read in function\n",
    "\n",
    "def DataReadIn(filename):\n",
    "    '''\n",
    "        Takes txt file located at filename and extracts the data from file\n",
    "    '''\n",
    "    f = open(filename + '.txt')\n",
    "    raw_data = f.read()\n",
    "    f.close()\n",
    "    data = raw_data.splitlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd531f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_data = DataReadIn('foods')\n",
    "highfiber_data = DataReadIn('highfiber')\n",
    "lowfat_data = DataReadIn('lowfat')\n",
    "low_glycemic_index_data = DataReadIn('low-glycemic-index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b76ff",
   "metadata": {},
   "source": [
    "Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9816042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foods',\n",
       " 'Donut',\n",
       " 'Carrot',\n",
       " 'Strawberry',\n",
       " 'Doritos: Cool Ranch',\n",
       " 'Pasta',\n",
       " 'Blue Berry Muffin',\n",
       " 'Strawberry Smoothie',\n",
       " 'Chocolate Milk',\n",
       " 'Protein Bar',\n",
       " 'Orange Juice',\n",
       " 'Greek Salad',\n",
       " '',\n",
       " 'Takis',\n",
       " 'Popcorn',\n",
       " 'salmon2',\n",
       " 'pizza rolls',\n",
       " 'canteloupe',\n",
       " 'potatoes',\n",
       " 'watermelon',\n",
       " 'oatmeal',\n",
       " 'Slim Jims',\n",
       " 'Brussel Sprouts',\n",
       " 'Lasagna',\n",
       " 'Fried Chicken',\n",
       " 'Pizza Rolls',\n",
       " 'Bacon',\n",
       " 'French Fries',\n",
       " 'Skim Milk',\n",
       " 'Green Beans',\n",
       " 'ja&ng',\n",
       " 'Doritos: Nacho Cheese',\n",
       " 'Hot Sauce',\n",
       " 'Sriacha']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6261f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high fiber',\n",
       " 'no',\n",
       " 'yes ',\n",
       " 'yes ',\n",
       " 'nO',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes ',\n",
       " 'no',\n",
       " 'no',\n",
       " '',\n",
       " 'no',\n",
       " 'yes ',\n",
       " 'yes  ',\n",
       " 'no',\n",
       " 'yes  ',\n",
       " 'no',\n",
       " 'yes  ',\n",
       " 'yes',\n",
       " 'yEs',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes  ',\n",
       " '23314',\n",
       " 'no',\n",
       " 'No',\n",
       " 'yes  ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highfiber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff4c13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low fat',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'No',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " '',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes ',\n",
       " 'yes ',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes ',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes ',\n",
       " 'sa2e ',\n",
       " 'no',\n",
       " 'yeS ',\n",
       " 'yes ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowfat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f95b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low fat',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'No',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " '',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes ',\n",
       " 'yes ',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes ',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes ',\n",
       " 'sa2e ',\n",
       " 'no',\n",
       " 'yeS ',\n",
       " 'yes ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowfat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8764a",
   "metadata": {},
   "source": [
    "## Part 2: Clean Your Data\n",
    "The data in the files have one or more of the following issues:\n",
    "* Duplicate data\n",
    "* Missing data\n",
    "* Corrupted data\n",
    "Please do not change the data files. Read the files into Python data structures and then clean them using Python. You may not use Panda for this exercise. You may delete rows missing data, but you must make sure you delete the same position in each of your four lists. Create a list of Dictionaries from these shared lists.\n",
    "\n",
    "Inside of each dictionary, create a key-value pair. The key will be the first row of the file(which also would be the header), while the value will be the corresponding line number position in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60491f5d",
   "metadata": {},
   "source": [
    "While scanning the lists above, you may have noticed that:\n",
    "* `food_data` has missing data, duplicates, inconsistent casing, and some corrupted data\n",
    "* `highfiber_data` has missing data, inconsistent casing, some corrupted data, extra whitespace in strings (, and duplicates judging from `food-data`)\n",
    "* `lowfat_data` has missing data, inconsistent casing, some corrupted data, extra whitespace in strings (, and duplicates judging from `food_data`)\n",
    "* `low_glycemic_index_data` has missing data, inconsistent casing, and corrupted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac2220",
   "metadata": {},
   "source": [
    "We will set up a workflow to clean the data, starting with the common issues amongst the lists\n",
    "\n",
    "1. Whitespace: Define a function that takes list and returns said list with elements not having extra whitespace\n",
    "\n",
    "2. Character casing: Define a function that takes list and specified casing, and returns said list with elements adjusted to specified casing.\n",
    "\n",
    "3. Missing data: Create a function that takes in a list and finds where data is missing then removes that element-space/position for the fed-in list and those associated (e.g. takes in `food_data` and finds missing data at position i, removes element in position i from `food_data`, `highfiber_data`, `lowfat_data`, `low_glycemic_index_data`)\n",
    "\n",
    "4. Corrupted data: Create a function that takes in a list and finds where data is corrupted then removes that element-space/position for the fed-in list and those associated (e.g. takes in `food_data` and finds corrupted data at position j, removes element in position j from `food_data`, `highfiber_data`, `lowfat_data`, `low_glycemic_index_data`)\n",
    "\n",
    "5. Duplicate data: Create a function that finds a duplicate entry of an element in a list by counting how often each element appears and removing those that appear more than once along with the associated positions in other lists\n",
    "\n",
    "**Note:** Can combine 3 and 4 into single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3263736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whitespace removal function\n",
    "\n",
    "def RemoveWhitespace(data_list):\n",
    "    for i, item in enumerate(data_list[1:]):\n",
    "        data_list[i+1] = item.strip()\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cec11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_food_data = RemoveWhitespace(food_data)\n",
    "ws_highfiber_data = RemoveWhitespace(highfiber_data)\n",
    "ws_lowfat_data = RemoveWhitespace(lowfat_data)\n",
    "ws_low_glycemic_index_data = RemoveWhitespace(low_glycemic_index_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb60f52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high fiber',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'nO',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " '',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yEs',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " '23314',\n",
       " 'no',\n",
       " 'No',\n",
       " 'yes']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_highfiber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ee620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character casing function\n",
    "\n",
    "def CharacterCasing(data_list, casing='title'):\n",
    "    '''\n",
    "        data_list: list\n",
    "        casing: str\n",
    "        \n",
    "        takes in data_list and applies element-wise casing; current options are title and lower\n",
    "    '''\n",
    "    \n",
    "    if casing == 'title':\n",
    "        for i, item in enumerate(data_list[1:]):\n",
    "            data_list[i+1] = item.title()\n",
    "    elif casing == 'lower':\n",
    "        for i, item in enumerate(data_list[1:]):\n",
    "            data_list[i+1] = item.lower()\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d13dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_food_data = CharacterCasing(ws_food_data, casing='title')\n",
    "c_highfiber_data = CharacterCasing(ws_highfiber_data, casing='lower')\n",
    "c_lowfat_data = CharacterCasing(ws_lowfat_data, casing='lower')\n",
    "c_low_glycemic_index_data = CharacterCasing(ws_low_glycemic_index_data, casing='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a7cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high fiber',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " '',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " '23314',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_highfiber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218a991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing/Corrupted data cleaning function\n",
    "\n",
    "def RemoveMissCorrData(data_list, list1=None, list2=None, list3=None):\n",
    "    '''\n",
    "        data_list: list\n",
    "        list1: list or None\n",
    "        \n",
    "        takes in data_list and identifies index where the element is not alphabetic.\n",
    "        Then uses said index to delete entries in data_list and associated list1, list2, etc.\n",
    "        If list1, etc. not specified, defaults to None\n",
    "    '''\n",
    "    \n",
    "    indices = []\n",
    "    for i, item in enumerate(data_list[1:]):\n",
    "        if not item.isalpha():\n",
    "            print(data_list[i+1])\n",
    "            indices.append(i+1)\n",
    "            \n",
    "    indices.reverse()\n",
    "    for j in indices:\n",
    "        print(data_list[j])\n",
    "        del list3[j]\n",
    "        del list2[j]\n",
    "        del list1[j]\n",
    "        del data_list[j]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29c659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23314\n",
      "23314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RemoveMissCorrData(c_highfiber_data, list1=c_food_data, list2=c_lowfat_data, list3=c_low_glycemic_index_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d08f5db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(c_food_data))\n",
    "print(len(c_highfiber_data))\n",
    "print(len(c_lowfat_data))\n",
    "print(len(c_low_glycemic_index_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10c749df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low glycemic index',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_low_glycemic_index_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c78f4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
